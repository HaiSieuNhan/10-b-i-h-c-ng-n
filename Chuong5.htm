<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title></title>
</head>
<body>
<h1 style="text-align: center;">&nbsp;05 HIỂU THẾ GIỚI</h1>
<p style="text-align: justify;"><span style="font-weight: bold;">“Chúng ta sẽ xem qua xem mình có cần hiểu những gì nhìn thấy hay không.”</span></p>
<p style="text-align: right;">&nbsp;HENRY DAVID THOREAU</p>
<p style="text-align: justify;">Với chiều dài chỉ 1/5 milimet, kích cỡ mà mắt thường không thể nhìn thấy, nó nhỏ hơn cả amip đơn bào. Tuy nhiên, nó có đôi mắt với đầy đủ chức năng. Nó có đôi cánh mềm mại – với chỉ vài sợi lông mịn – đủ để đẩy nó đi trong không khí giàu hơi nước. Quá nhỏ để có một trái tim, máu của nó lưu thông hoàn toàn bằng cách khuếch tán. Nó nhận thức thế giới của mình đủ tốt để tìm thức ăn, bạn tình và vật chủ để đẻ trứng. Khả năng hiểu thế giới của nó được kích hoạt nhờ bộ não nhỏ nhất so với bất kỳ loài côn trùng và sinh vật bay nào khác, với chỉ 7.400 neuron. Tuy nhiên, các neuron này không có đủ chỗ trong một cơ thể nhỏ bé, vì vậy, đến giai đoạn phát triển cuối cùng, nó sẽ loại bỏ phần nhân thiết yếu bên trong mỗi neuron để tiết kiệm không gian. Đây là loài Megaphragma mymaripenne kỳ lạ, một loại ong bắp cày nhỏ và là loài côn trùng nhỏ thứ ba từng được biết đến.</p>
<p style="text-align: justify;">&nbsp;Hiện chúng ta vẫn chưa hiểu được làm thế nào chỉ với vài neuron ít ỏi mà chúng có thể nhận thức và kiểm soát một cách phức tạp đến thế. Megaphragma mymaripenne (hiếm khi được nghiên cứu đến nỗi còn không có tên tiếng Anh thông dụng – ta hãy tạm gọi nó là Wisp Wasp, Ong Còi) là một loài côn trùng siêu nhỏ với những khả năng mà không robot nào có thể sánh được, nhưng bằng cách nào đó, bộ máy nhận thức của nó xem ra đơn giản hơn AI ngày nay.&nbsp;</p>
<h1 style="text-align: justify;">Cảm biến</h1>
<p style="text-align: justify;">Nhận thức là một khía cạnh quan trọng của AI. Khi không có khả năng nhận thức thế giới bên ngoài, AI của chúng ta chỉ có thể sống trong thế giới kỹ thuật số, suy nghĩ về những dữ liệu chuyên biệt không liên quan với thực tế. Các giác quan kết nối chúng với thế giới của chúng ta. Máy ảnh cung cấp cho chúng khả năng nhìn, micrô mang lại khả năng nghe, cảm biến áp suất cung cấp xúc giác còn gia tốc kế thì cung cấp khả năng định hướng. Trong những năm qua, chúng ta cũng đã phát triển nhiều loại cảm biến kỳ lạ, thường được sử dụng trong khoa học và kỹ thuật. Điều này có nghĩa là AI có thể sở hữu nhiều giác quan hơn chúng ta. Ví dụ: hầu hết các phương tiện tự hành đều sử dụng LIDAR (máy quét laser 3D) để phát hiện và định vị các đối tượng bất kể độ sáng. Máy ảnh có thể cảm nhận các tần số ánh sáng mà mắt người không thể nhìn thấy, cho phép AI cảm thụ nhiệt hoặc sóng vô tuyến. Các cảm biến được gắn trong động cơ, hệ thống GPS, và phép đạc tam giác (triangulation) qua các trạm sóng cùng tín hiệu Wi-Fi giúp AI hiểu chính xác vị trí của chúng trên hành tinh và tốc độ mà chúng đang di chuyển. Và tuy robot không cần ăn nhưng các cảm biến hóa học vẫn cho phép phát hiện hóa chất chính xác hơn mũi hoặc lưỡi của chúng ta.&nbsp;</p>
<p style="text-align: justify;">Các cảm biến đóng vai trò cực kỳ quan trọng, nhưng chỉ là bước đầu tiên của nhận thức. Khi phát hiện đặc trưng nào đó của thế giới bên ngoài, các cảm biến sẽ tạo ra tín hiệu điện và chuyển đổi thành dữ liệu – hàng triệu bit 0 và 1 – rồi truyền tới AI. Cũng giống như bộ não của bạn phải biến đổi tín hiệu từ các photon &nbsp;đập vào võng mạc thành các thông tin có thể hiểu được, AI phải hiểu được dữ liệu liên tục chảy vào bộ não kỹ thuật số của nó.&nbsp;</p>
<p style="text-align: justify;"><span style="font-weight: bold;">“Có một công ty thời trang đang gắn cảm biến lên áo quần của bạn. Họ sẽ theo dõi cách bạn ngồi, chạy hoặc trượt tuyết để thu thập dữ liệu về những thông tin đó.”&nbsp;</span></p>
<p style="text-align: right;">ROBERT SCOBLE Nhà truyền bá công nghệ của Microsoft từ 2003 đến 2006</p>
<h1>Học cách nhìn&nbsp;</h1>
<p style="text-align: justify;">Công việc ban đầu của thị giác máy (computer vision) là tập trung vào việc chia nhỏ hình ảnh thành các yếu tố cấu thành, giống như cách (người ta nghĩ) mắt người hoạt động. Các thuật toán được tạo ra để kiểm tra một lượng lớn thông tin dường như không liên kết với nhau và tìm ra các cạnh hoặc ranh giới giữa các vùng trong hình ảnh.</p>
<div style="text-align : center">
    <img src="Anh20.png" alt="" style="width : 40%"/></div>
<div style="text-align : center"><span style="font-style: italic; font-weight: bold;">Thị giác máy phân tích hình ảnh</span><br/></div>
<div style="text-align : center"><span style="font-style: italic;"><br/></span></div>
<div style="text-align : center"><div style="text-align : center">
    <img src="Anh21.png" alt="" style="width : 60%"/></div>
<div style="text-align : center"><br/></div>
<div style="text-align : center"><div style="text-align: justify;">Ngoài khả năng phát hiện cạnh (edge detection), thị giác máy đã phát triển nhiều thuật toán thông minh để phát hiện các dạng hình học và sau đó phân đoạn hình ảnh thành các vùng có thể nhận dạng rõ ràng. Các thuật toán được phát triển để tìm khoảng cách từ máy ảnh lập thể, theo dõi các đối tượng chuyển động và xây dựng các mô hình 3D theo chiều sâu của cảnh vật từ một số hình ảnh được chụp từ các góc khác nhau. Theo sau là sự ra đời của các phương pháp thống kê, và các phương pháp nhận dạng khuôn mặt bằng cách tạo một tập hợp các “đặc trưng khuôn mặt thông thường” (các hình ảnh cơ bản hoặc các khuôn mặt đặc trưng – eigenfaces).&nbsp;</div>
<div style="text-align: justify;">Tất cả các phương pháp này đều rất thông minh. Chúng cho phép robot di chuyển với mức độ tự tin cao hơn nhiều vì AI giờ đây có thể nhận ra các hình thù đơn giản và nắm bắt được vị trí xung quanh. Các phương pháp tương tự cũng bắt đầu cho phép nhận dạng chữ viết tay và giọng nói. Nhưng hầu hết các phương pháp tiếp cận vẫn hoạt động kém trong điều kiện ánh sáng yếu hoặc khi dữ liệu do cảm biến thu thập không hoàn hảo – một điều rất phổ biến ở robot. Chúng ta cần thứ gì đó tốt hơn.</div>
<h1 style="text-align: justify;">Các máy tính có não</h1>
<div style="text-align: justify;">&nbsp;Câu trả lời đến từ thiên nhiên. Kể từ thời kỳ đầu của trí tuệ nhân tạo, các nhà nghiên cứu như Warren McCulloch, Walter Pitts, Marvin Minsky và Frank Rosenblatt đã tạo ra các bản mô phỏng neuron đơn giản trên máy tính được kết nối với nhau với tham vọng tạo ra khả năng học tập giống như bộ não sinh học. Trong khi các mạng lưới thần kinh đầu tiên quá đơn giản (gây ra một số thất vọng về mặt kỹ thuật như một cuốn sách nổi tiếng của Minsky từng đề cập, đã được mô tả trong chương 01), các nhà nghiên cứu vẫn tiếp tục phát triển các phương pháp này. Bản thân mô hình neuron cũng dần phức tạp hơn và các cách huấn luyện neuron tốt hơn đã được phát triển.</div>
<div style="text-align: justify;">Mạng lưới thần kinh nhân tạo (ANN – Artificial Neural Network) trở thành một loại AI đã được khẳng định và rất thành công. Để hoạt động, mạng ANN được mô phỏng theo cách hoạt động của bộ não sinh học ở cấp độ tối giản. Hầu hết các bộ phận phức tạp đều bị loại bỏ – không có cấu trúc hóa học, tế bào hỗ trợ, nguồn cung cấp máu và không có các liên kết bằng xung điện giữa các neuron với nhau. Phần còn lại có thể coi là một ý tưởng trừu tượng về một neuron nhân tạo, hoạt động hơi giống một hàm toán học. Khi được cung cấp một vài số liệu đầu vào, nó kết hợp các thông tin này với trạng thái hiện tại và tạo ra dữ liệu xuất bằng cách sử dụng một hàm toán học được gọi là hàm kích hoạt (activation function, một hàm phi tuyến như sigmoid, hàm hyperbol tiếp tuyến hoặc một đơn vị kích hoạt chỉnh lưu tuyến tính). Các “neuron” này được kết nối với nhau thành mạng lưới, trong đó các hàng của lớp neuron đầu vào tiếp nhận dữ liệu, ví dụ: hình ảnh từ máy ảnh được truyền từ hàng này qua hàng khác trong các lớp ẩn (hidden layer), cuối cùng được truyền đến một số lượng nhỏ các neuron xuất để cung cấp kết quả tổng thể – có thể giúp phân loại thông tin đầu vào hoặc tín hiệu điều khiển cho robot.</div>
<div style="text-align: justify;"><br/></div>
 <img src="Anh22.png" alt="" style="width : 60%"/></div>
<div style="text-align : center"><br/></div>
<div style="text-align : center"><div style="text-align: justify;">Các mạng lưới thần kinh sẽ học hỏi bằng cách thay đổi trọng số của kết nối giữa các neuron, chọn ra các kết nối nào quan trọng tùy theo các dữ kiện đầu vào. Tối ưu hóa trọng số kết nối (giá trị cho biết tầm quan trọng của mỗi kết nối) và độ lệch (bias) (là một cách khác để sửa đổi tác động của hàm kích hoạt) sao cho neuron đưa ra câu trả lời chính xác khi tiếp nhận “dữ liệu huấn luyện”. Kết quả là một mạng lưới thần kinh đã được huấn luyện hoạt động chuẩn theo dữ liệu đầu vào mới mà chúng chưa từng trải nghiệm trước đây. Các mạng như vậy được gọi là mạng truyền thẳng (feedforward) vì mỗi lớp neuron chỉ kết nối với lớp tiếp theo, và không truyền ngược lại. Có một phương pháp phổ biến để huấn luyện loại mạng lưới thần kinh truyền thẳng này được gọi là truyền ngược (backpropagation), trong đó máy tính bắt đầu từ các neuron ở đầu ra và truyền qua các lớp neuron để hướng về phía đầu vào, giúp cập nhật trọng số và độ lệch để giảm thiểu lỗi ở đầu ra.&nbsp;</div>
<div style="text-align: justify;">Một trong những vấn đề lớn nhất khi huấn luyện mạng lưới thần kinh là cung cấp cho nó dữ liệu phù hợp. Ban đầu, công việc này được thực hiện bằng cách cố gắng trích xuất cẩn thận các đặc trưng có ý nghĩa – tức là các cạnh, các dạng hình học và khoảng cách được trích xuất từ một hình ảnh bằng các thuật toán khác, sau đó mới đưa vào mạng lưới thần kinh. Mạng lưới thần kinh có chức năng thị giác thường được huấn luyện bằng phương pháp học có giám sát (supervised learning): nếu chúng ta muốn có một bộ phân loại đơn giản xuất ra 1 khi hình ảnh một con mèo được hiển thị và 0 khi hình ảnh một con chó được hiển thị, thì ta cần cung cấp hàng trăm hoặc hàng nghìn ví dụ về mèo và chó, sau đó điều chỉnh mạng lướithần kinh (chẳng hạn bằng cách sử dụng phương pháp truyền ngược) cho đến khi nó xuất chính xác giá trị 1 khi “nhìn thấy” một con mèo và 0 khi “nhìn thấy” một con chó. Việc ứng dụng phương pháp học có giám sát như vậy đóng vai trò then chốt vì chúng ta muốn giám sát quá trình huấn luyện để đảm bảo nó học chính xác những gì chúng ta muốn. Tuy nhiên, phương pháp này chỉ thực sự thành công khi mạng lưới thần kinh được tạo ra có cách kết nối giống với các neuron trong vỏ não thị giác của sinh vật.</div>
<div style="text-align: center;"><br/></div>
<div style="text-align : center">
    <img src="Anh23.png" alt="" style="width : 40%"/></div>
<div style="text-align : center"><div><span style="font-style: italic; font-weight: bold;">Mạng lưới thần kinh</span></div>
<div><br/></div>
<div style="text-align: justify;"><span style="font-weight: bold;">“Bộ não chắc chắn không hoạt động theo các quy tắc chết tiệt nào được lập trình bởi bất kỳ ai.”</span>&nbsp;</div>
<div style="text-align: right;">GEOFFREY HINTON (2017)</div>
<div style="text-align: justify;"><br/></div>
<div style="text-align: justify;">Người ta đã khám phá ra rằng đôi mắt được kết nối với bộ não theo những cách khá thông minh. Thay vì chỉ một tế bào cảm thụ ánh sáng trong võng mạc (hình que hoặc hình nón) được liên kết đến một neuron, các vùng sẽ được kết nối với từng neuron. Các neuron lân cận được kết nối với các vùng chồng chéo nằm gần nhau trong võng mạc. Sau đó, những neuron này cung cấp thông tin cho một lớp neuron mới, mà mỗi neuron trong lớp mới này được kết nối với một nhóm các neuron lân cận trong lớp trước đó. Tới lượt mình, chúng cung cấp các thông tin cho một lớp neuron mới khác, với mỗi neuron trong lớp mới một lần nữa được kết nối với một tập hợp các neuron lân cận trong lớp trước đó, và cứ thế. Đây là một cách rất khác để kết nối mạng lưới thần kinh so với cách kết nối liền mạch của mạng truyền thẳng truyền thống. Khi các mạng lưới thần kinh nhân tạo được kết nối theo cách này với hàng loạt các lớp neuron và rất nhiều dữ liệu đầu vào, đột nhiên khả năng của chúng sẽ biến đổi.</div>
<div style="text-align: justify;"><br/></div>
<div style="text-align : center">
    <img src="Anh24.png" alt="" style="width : 40%"/></div>
<div style="text-align: center;"><div><span style="font-style: italic; font-weight: bold;">Kết nối mạng lướii thần kinh</span></div>
<div><br/></div>
<div style="text-align: justify;">Các mạng lưới thần kinh như vậy được gọi là mạng lưới thần kinh tích chập (convolutional neural network) – một loại học sâu thường được sử dụng cho thị giác máy. (Gọi là học “sâu” vì nó có rất nhiều lớp neuron.) Kích thước không giới hạn của chúng khiến việc huấn luyện diễn ra rất chậm và cần rất nhiều dữ liệu đầu vào. Nhưng trong những năm gần đây, cả hai vấn đề này đã được giải quyết.&nbsp;</div>
<div style="text-align: justify;">Kỷ nguyên dữ liệu lớn khiến việc cung cấp dữ liệu cho các mạng lưới thần kinh trở nên dễ dàng – có hàng triệu ví dụ về hầu hết mọi loại hình ảnh bạn muốn, bất kể là biển số xe, các ký tự trong bảng chữ cái hay mặt người. Và điều đáng ngạc nhiên là thứ vốn được ngành công nghiệp trò chơi máy tính giải quyết vấn đề tốc độ xử lý bằng cách tạo ra các bộ xử lý đồ họa máy tính siêu nhanh – đã được các nhà nghiên cứu mạng lưới thần kinh khám phá và tái sử dụng để thực hiện các phép tính liên quan đến việc huấn luyện neuron. Đến năm 2012, máy tính đã vượt qua khả năng thị giác của con người – chúng có thể nhận diện các vật thể trong hình ảnh với độ chính xác siêu phàm. Mạng lưới thần kinh tích chập sâu (convolutional deep neural network) hiện nay thông minh đến mức chúng ta không cần phải xác định trước các đặc trưng trong hình ảnh nữa. Chúng có thể tự tìm ra tất cả.</div>
<div style="text-align: justify;"><br/></div>
<div style="text-align: justify;"><span style="font-weight: bold;">“Những tiến bộ trong thị giác máy hiện nay đang tạo ra những cơ hội to lớn và mới mẻ trong việc phân tích hình ảnh, chúng đang tác động theo cấp số nhân đến mọi ngành kinh doanh, từ ô tô, quảng cáo đến thực tế tăng cường (AR).”&nbsp;</span></div>
<div style="text-align: right;">EVAN NISSELSON Chuyên gia truyền thông kỹ thuật số và nhà đầu tư (2016)</div>
<div style="text-align: right;"><br/></div>
<div style="text-align: justify;">Ngày nay, những tiến bộ trong thị giác máy là điều mà ai cũng thấy. Các sản phẩm và dịch vụ đáng kinh ngạc xung quanh chúng ta dựa trên các phương pháp AI này, từ nhận dạng khuôn mặt trong điện thoại đến việc số hóa nhanh chóng hầu hết các cuốn sách và bản viết tay trên thế giới, từ việc phát hiện chướng ngại vật của xe tự lái đến nhận dạng các dạng khối u trong chẩn đoán y khoa. Các nhà máy của chúng ta ngày càng dựa vào các hệ thống thị giác tiên tiến này để phát hiện lỗi trong quá trình sản xuất nhằm kiểm soát chất lượng và các nhà máy tái chế sử dụng thị giác máy để cho phép robot phân chia rác thải thành các loại phù hợp. Thậm chí còn có một số kết quả phi thường về phân loại tín hiệu điện não đồ (EEG) cho phép con người điều khiển một cánh tay robot bằng ý nghĩ. Công nghệ này có thể tạo ra một dạng tay chân giả hoàn toàn mới. Các kỹ thuật mạng lưới thần kinh tương tự cũng đã biến đổi quá trình xử lý các dữ liệu cảm biến khác như nhận dạng giọng nói (xem chương 07). Các thuật toán học có giám sát vẫn đang phát triển mạnh mẽ, thậm chí còn có các biến thể mới hơn như mạng lưới thần kinh capsule (capsule neural network) bổ sung thêm cấu trúc phân cấp lấy cảm hứng từ sinh học vào mạng tích chập, khiến chúng trở nên mạnh mẽ hơn nữa.</div>
<h1 style="text-align: justify;">&nbsp;Máy tính phân biệt chủng tộc?</h1>
<div style="text-align: justify;">Học có giám sát (sử dụng mạng lưới thần kinh tích chập và tổng hòa các phương pháp khác) đã tạo nên một cuộc cách mạng trong lĩnh vực AI và robot. Điều hấp dẫn nhưng xen chút lo ngại là những kỹ thuật này cũng phản ánh chính bản thân và thành kiến của chúng ta. Mặc dù có dữ liệu khổng lồ, nhưng do thành kiến xã hội, các AI thường được huấn luyện dựa trên hình ảnh chủ yếu của những người đàn ông có làn da sáng màu, nhiều hơn hẳn các giới tính hoặc màu da khác. Kết quả là AI nhận dạng khuôn mặt chính xác gần như tuyệt đối với những đối tượng này, nhưng lại thất bại thảm hại đối với những phụ nữ có làn da sẫm màu. Trong các thử nghiệm gần đây, các hệ thống AI từ các công ty hàng đầu như IBM, Microsoft và Amazon đã nhận dạng sai khuôn mặt của Oprah Winfrey, Michelle Obama và Serena Williams, trong khi không gặp chút khó khăn nào với nam giới da trắng.</div>
<div style="text-align: justify;"><br/></div>
<div style="text-align: justify;"><span style="font-weight: bold;">“Tôi đã trải nghiệm trực tiếp điều này khi đang là sinh viên tại MIT vào năm 2015 và phát hiện ra rằng một số phần mềm phân tích khuôn mặt không thể phát hiện ra khuôn mặt ngăm đen của tôi cho đến khi tôi đắp mặt nạ trắng.”&nbsp;</span></div>
<div style="text-align: right;">JOY BUOLAMWINI Nhà nghiên cứu AI (2019)</div>
<div><br/></div>
<div style="text-align: justify;">Khi bộ dữ liệu được sử dụng để huấn luyện AI của chúng ta bị sai lệch một cách khủng khiếp (như một bộ dữ liệu của chính phủ Hoa Kỳ về các khuôn mặt được thu thập để huấn luyện AI với đến 75% nam giới và 80% cá nhân có làn da sáng), kết quả dự đoán sẽ thiếu chính xác. Trong quy trình học có giám sát, AI chỉ có thể trở thành thứ mà chúng được huấn luyện để trở thành. Điều này có thể gây ra hậu quả hiển nhiên và rõ ràng nếu thị giác máy được sử dụng cho các ứng dụng an ninh hoặc cảnh sát, nơi mà một sự thiên lệch tiêu cực có thể dẫn đến kết quả nhận dạng sai đối với một số nhóm người nhất định. Nếu không nói giọng bản ngữ, giọng nói của bạn sẽ khó bị nhận dạng hơn rất nhiều.</div>
<div style="text-align: justify;">&nbsp;Thị giác máy không nhất thiết phải được thực hiện bằng cách sử dụng phương pháp học có giám sát (xem chương tiếp theo), nhưng trong nhiều ứng dụng đây là giải pháp hợp lý. Khi gửi các mạng lưới thần kinh nhân tạo của mình đến “trường học”, chúng ta phải cung cấp một trải nghiệm đủ rộng để chúng có thể hoạt động hiệu quả. Giáo viên tồi sẽ tạo ra những AI tồi.</div>
<div style="text-align: justify;">Đáng buồn thay, những thành kiến vẫn còn phổ biến trong xã hội của chúng ta. Trong các ngành khoa học và kỹ thuật máy tính, các lớp học và giảng đường đại học vẫn chủ yếu là sinh viên nam, chỉ có 15% sinh viên là nữ ở Anh – một xu hướng không hề thay đổi trong vài năm qua. Kết quả là vẫn có nhiều nam giới tiên phong về AI hơn nữ giới – thực trạng lệch lạc đó được phản ánh rõ nét trong cuốn sách này. Chắc chắn đã đến lúc để khôi phục sự cân bằng!</div>
<div style="text-align: justify;">&nbsp;Sự thiên lệch trong huấn luyện không phải là vấn đề duy nhất gắn với thị giác máy. Ngày nay, các thuật toán deepfake có thể thay thế liền mạch khuôn mặt của một người bằng khuôn mặt của người khác trong các video. Được sử dụng nhiều trong phim khiêu dâm, công nghệ này còn được dùng để bôi xấu các chính trị gia hoặc thực hiện hành vi gian lận. Việc phân biệt thực tế và giả mạo chưa bao giờ khó đến thế. Tại Hoa Kỳ, điều này đã dẫn đến các quy định mới: Đạo luật Cấm Deep Fake Độc hại (Malicious Deep Fake Prohibition Act) được đưa ra trước Thượng viện Mỹ năm 2018 và Đạo luật về Trách nhiệm DEEPFAKES (DEEPFAKES Accountability Act) được giới thiệu tại Hạ viện năm 2019.</div>
<div style="text-align: justify;">&nbsp;Dù muốn hay không, thị giác máy đã đạt được thành công vang dội. Mặc dù có những thành kiến và lạm dụng, ngày nay đôi khi có cảm giác như thể thị giác máy là một vấn đề đã được giải quyết trong lĩnh vực kiến trúc mạng lưới thần kinh. Nhưng trong khi chúng ta có thể kết nối chúng theo những cách giống với vỏ não thị giác, mạng lưới thần kinh nhân tạo trông thật ngu ngốc so với phiên bản thực tế. Các phương pháp của chúng ta hoạt động, nhưng thường phải can thiệp một cách thô bạo lên một khối dữ liệu khổng lồ, sử dụng hàng nghìn neuron nhân tạo và sức mạnh tính toán khổng lồ để huấn luyện chúng. Chú ong Wisp Wasp nhỏ bé cho chúng ta thấy rằng có rất nhiều cách tao nhã và đơn giản hơn để cảm nhận về thế giới. Chúng ta vẫn còn nhiều điều cần học hỏi.</div>
<div style="text-align: justify;"><br/></div>
</div>
<div style="text-align: justify;"><br/></div>
<div style="text-align: center;"><br/></div>
</div>
<div style="text-align: justify;"><br/></div>
<div style="text-align: justify;"><br/></div>
<div style="text-align: justify;"><br/></div>
<div style="text-align: justify;"><br/></div>
</div>
<div style="text-align: justify;"><br/></div>
<div style="text-align: justify;"><br/></div>
<div style="text-align: justify;"><br/></div>
<div style="text-align: center;"><br/></div>
<div><br/></div>
</div>
<span style="font-style: italic;"><br/></span>
<div style="text-align : center"><span style="font-style: italic;"><br/></span></div>
<div style="text-align : center"><span style="font-style: italic;"><br/></span></div>
<p style="text-align: center;"><br/></p>
<div><br/></div>
</body>
</html>